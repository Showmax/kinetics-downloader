{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "BASE_DIR = Path.cwd().parent\n",
    "STATS_DIR = BASE_DIR / 'stats'\n",
    "KINETICS_DIR = BASE_DIR / 'work_dir' / 'kinetics_700'\n",
    "KINETICS_DIR = Path('/home/gitumarkk/Desktop/GITHUB/dance-datasets-downloader/resources/700')\n",
    "GIF_DIR = Path('/home/gitumarkk/Desktop/WORK_DIR/kinetics_gif/train_180_16')\n",
    "VIDEO_PATH = Path('/media/gitumarkk/Seagate Backup Plus Drive/Dancelogue/DATASETS/Kinetics')\n",
    "\n",
    "DATA_PATH = Path('/home/gitumarkk/Desktop/WORK_DIR/kinetics_gif/train_180_16_json')\n",
    "DATA_PATH.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results_file(source):\n",
    "    with source.open(mode='r') as results_json:\n",
    "        data = json.load(results_json)\n",
    "    return data\n",
    "\n",
    "def read_kinetics_data():\n",
    "    all_data = {}\n",
    "    for f1 in KINETICS_DIR.iterdir():\n",
    "        if f1.stem in ['train', 'val', 'test']:\n",
    "            for f2 in f1.iterdir():\n",
    "                if f2.suffix == '.json':\n",
    "                    data = read_results_file(f2)\n",
    "                    all_data.update(data)\n",
    "    return all_data\n",
    "\n",
    "kinetics_data = read_kinetics_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646984\n"
     ]
    }
   ],
   "source": [
    "print(len(kinetics_data.keys()))\n",
    "kinetics_keys_dict = {key: True for key in kinetics_data.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gif_data():\n",
    "    gif_dict = {}\n",
    "    for f1 in GIF_DIR.iterdir():\n",
    "        if f1.is_dir():\n",
    "            for f2 in f1.iterdir():\n",
    "                gif_dict[f2.stem] = f2\n",
    "    return gif_dict\n",
    "\n",
    "gif_data = get_gif_data()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532185\n"
     ]
    }
   ],
   "source": [
    "print(len(gif_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def move_gif_not_in_700():\n",
    "    GIF_DIR_MISSING = GIF_DIR.parent / 'train_not_in_700'\n",
    "    GIF_DIR_MISSING.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    m = 0\n",
    "    for key in gif_data.keys():\n",
    "        if not kinetics_keys_dict.get(key):\n",
    "            na = gif_data[key]\n",
    "            (GIF_DIR_MISSING / na.parent.stem).mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            shutil.move(str(na), str(GIF_DIR_MISSING / na.parent.stem / na.name))\n",
    "            print(gif_data[key])\n",
    "            m += 1\n",
    "    print(m)\n",
    "    \n",
    "move_gif_not_in_700()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_json():\n",
    "    output = {}\n",
    "    for f1 in GIF_DIR.parent.iterdir():\n",
    "        if f1.stem in ['train_180_16']:\n",
    "            for f2 in f1.iterdir():\n",
    "                output[f2.stem] = []\n",
    "\n",
    "                for f3 in f2.iterdir():\n",
    "                    try:\n",
    "                        img = Image.open(str(f3))\n",
    "                        output[f2.stem].append({\n",
    "                          'g': f3.name,\n",
    "                          'w': img.width,\n",
    "                          'h': img.height\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "\n",
    "                with (DATA_PATH / \"{}.json\".format(f2.stem)).open(mode='w') as f2_json:\n",
    "                    json.dump(output[f2.stem], f2_json)\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "# create_train_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_data():\n",
    "    gif_dict = {}\n",
    "    for f1 in VIDEO_PATH.iterdir():\n",
    "        if f1.stem in ['train', 'val', 'test']:\n",
    "            for f2 in f1.iterdir():\n",
    "                if f1.stem == 'test':\n",
    "                    gif_dict[f2.stem] = {\n",
    "                        'path': f2,\n",
    "                        'split': f1.stem\n",
    "                    }\n",
    "                else:\n",
    "                    for f3 in f2.iterdir():\n",
    "                        gif_dict[f3.stem] = {\n",
    "                            'path': f3,\n",
    "                            'split': f1.stem\n",
    "                        }\n",
    "    return gif_dict\n",
    "\n",
    "video_data = get_video_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645090\n"
     ]
    }
   ],
   "source": [
    "print(len(video_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13486\n"
     ]
    }
   ],
   "source": [
    "def move_video_not_in_700():\n",
    "    VIDEO_DIR_MISSING = VIDEO_PATH / 'train_not_in_700'\n",
    "    \n",
    "    for s in ['train', 'test', 'val']:\n",
    "       (VIDEO_PATH / \"{}_na\".format(s)).mkdir(exist_ok=True, parents=True)\n",
    "    #     GIF_DIR_MISSING.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    m = 0\n",
    "    for key in video_data.keys():\n",
    "        if not kinetics_keys_dict.get(key):\n",
    "            na = video_data[key]['path']\n",
    "            split = video_data[key]['split']\n",
    "            \n",
    "            shutil.move(str(na), str(VIDEO_PATH / \"{}_na\".format(split) / na.name))\n",
    "            \n",
    "            m += 1\n",
    "    print(m)\n",
    "    \n",
    "move_video_not_in_700()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
